{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector Add\n",
    "\n",
    "The vector addition kernel is one of the most simple GPU kernels and is therefore used to explain basic GPU programming concepts.\n",
    "\n",
    "In this exercise you start with reading through the code and look for something that needs to be implemented. We will start with doing some necessary imports of modules that we need to compile and run GPU code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pycuda.driver as drv\n",
    "from pycuda.compiler import SourceModule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize pycuda and create a device context\n",
    "drv.init()\n",
    "context = drv.Device(0).make_context()\n",
    "\n",
    "#get compute capability for compiling CUDA kernels\n",
    "devprops = { str(k): v for (k, v) in context.get_device().get_attributes().items() }\n",
    "cc = str(devprops['COMPUTE_CAPABILITY_MAJOR']) + str(devprops['COMPUTE_CAPABILITY_MINOR'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to implement our GPU kernel, which is written in the CUDA language. The following cell writes its contents to a file named vector_add.cu which we will later compile on the GPU into a GPU kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile vector_add.cu\n",
    "\n",
    "__global__ void vec_add_kernel(float *c, float *a, float *b, int n) {\n",
    "    int i = 0;   // Oops! Something is not right here, please fix it!\n",
    "    if (i < n) {\n",
    "        c[i] = a[i] + b[i];\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we continue with our GPU kernel we will setup the input and output data for our GPU kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = np.int32(5e7)\n",
    "a = np.random.randn(n).astype(np.float32)\n",
    "b = np.random.randn(n).astype(np.float32)\n",
    "c = np.zeros_like(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also measure the time it would take to compute an element-wise vector addition of a and b in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "d = a+b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets compile our CUDA kernel and see how long it takes to perform the same computation on the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first we allocate GPU memory and copy the data to the GPU\n",
    "args = [c, a, b]\n",
    "gpu_args = []\n",
    "for arg in args:\n",
    "    gpu_args.append(drv.mem_alloc(arg.nbytes))\n",
    "    drv.memcpy_htod(gpu_args[-1], arg)\n",
    "gpu_args.append(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before compiling our kernel we setup the kernel launch parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setup the thread block dimensions (x, y, z)\n",
    "threads = (1024, 1, 1)\n",
    "#setup the number of thread blocks in (x, y, z)\n",
    "grid = (int(np.ceil(n/float(threads[0]))), 1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now compile and run the kernel, measure the execution time, copy the data back from GPU memory to our Numpy array c and check if the result is correct.\n",
    "\n",
    "This is all in one cell because you will have to modify the CUDA source code and run this cell again to check if you've completed the assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we have to pass the source code as a string, so we first read it from disk\n",
    "with open('vector_add.cu', 'r') as f:\n",
    "    kernel_string = f.read()\n",
    "\n",
    "#compile the kernel\n",
    "vector_add = SourceModule(kernel_string, arch='compute_' + cc, code='sm_' + cc,\n",
    "                          cache_dir=False).get_function(\"vec_add_kernel\")\n",
    "\n",
    "#make sure the output data is clean\n",
    "c = np.zeros_like(b)\n",
    "drv.memcpy_htod(gpu_args[0], c)\n",
    "\n",
    "#Make sure all previous operations on the GPU have completed\n",
    "context.synchronize()\n",
    "#Create events for measuring time\n",
    "start = drv.Event()\n",
    "end = drv.Event()\n",
    "\n",
    "#Run the kernel\n",
    "start.record()\n",
    "vector_add(*gpu_args, block=threads, grid=grid, stream=None, shared=0)\n",
    "end.record()\n",
    "\n",
    "#Wait for the kernel to finish\n",
    "context.synchronize()\n",
    "\n",
    "#Print how long it took\n",
    "print(\"vec_add_kernel took\", end.time_since(start), \"ms.\")\n",
    "\n",
    "#copy output data back from GPU\n",
    "drv.memcpy_dtoh(c, gpu_args[0])\n",
    "\n",
    "#check for correctness\n",
    "print(\"PASSED\" if np.allclose(c, a+b, atol=1e-6) else \"FAILED\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
